{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Merging Timeseries With ``merge_dicts``\n",
    "\n",
    "``merge_dicts()`` combines timeseries data from different tasks and sessions, enabling analyses\n",
    "that identify similar CAPs across these tasks, sessions, or both. This is only useful when the tasks and sessions\n",
    "includes the same subjects. This function produces a merged dictionary only containing subject IDs present across all\n",
    "input dictionaries. Additionally, while the run IDs across task do not need to be similar, the timeseries of the same\n",
    "run-IDs across dictionaries will be appended. Note that successful merging requires all dictionaries to contain the\n",
    "same number of columns/ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download packages\n",
    "!pip install neurocaps[windows,demo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neurocaps.analysis import merge_dicts\n",
    "\n",
    "# Simulate two subject_timeseries dictionaries\n",
    "# First dictionary contains 3 subjects, each with three runs that have 10 timepoints and 100 rois\n",
    "subject_timeseries_session_pre = {str(x): {f\"run-{y}\": np.random.rand(10, 100) for y in range(3)} for x in range(3)}\n",
    "\n",
    "# Deleting run-2 for subject 2; situation where subject 2 only completed two runs of a task\n",
    "del subject_timeseries_session_pre[\"2\"][\"run-2\"]\n",
    "\n",
    "# Second dictionary contains 2 subjects, each with a single run that have 20 timepoints and 100 rois\n",
    "subject_timeseries_session_post = {str(x): {f\"run-{y}\": np.random.rand(20, 100) for y in range(1)} for x in range(2)}\n",
    "\n",
    "# The subject_timeseries_list also takes pickle files and can save the modified dictionaries as pickles too.\n",
    "subject_timeseries_merged = merge_dicts(\n",
    "    subject_timeseries_list=[subject_timeseries_session_pre, subject_timeseries_session_post],\n",
    "    return_merged_dict=True,\n",
    "    return_reduced_dicts=False,\n",
    ")\n",
    "\n",
    "for subj_id in subject_timeseries_merged[\"merged\"]:\n",
    "    for run_id in subject_timeseries_merged[\"merged\"][subj_id]:\n",
    "        timeseries = subject_timeseries_merged[\"merged\"][subj_id][run_id]\n",
    "        print(f\"sub-{subj_id}; {run_id} shape is {timeseries.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original dictionaries can also be returned too. The only modifications done is that the originals will\n",
    "# only contain the subjects present across all dictionaries in the list. Note that the \"dict_#\" IDs correspond\n",
    "# to the index that the subject timeseries are in `subject_timeseries_list`. `subject_timeseries_list` also\n",
    "# accepts pickle files\n",
    "merged_dicts = merge_dicts(\n",
    "    subject_timeseries_list=[subject_timeseries_session_pre, subject_timeseries_session_post],\n",
    "    return_merged_dict=True,\n",
    "    return_reduced_dicts=True,\n",
    ")\n",
    "\n",
    "for dict_id in merged_dicts:\n",
    "    for subj_id in merged_dicts[dict_id]:\n",
    "        for run_id in merged_dicts[dict_id][subj_id]:\n",
    "            timeseries = merged_dicts[dict_id][subj_id][run_id]\n",
    "            print(f\"For {dict_id} sub-{subj_id}; {run_id} shape is {timeseries.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAPs can be derived using the merged subject timeseries data. This analysis will identify CAPs present across session\n",
    "or tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurocaps.analysis import CAP\n",
    "\n",
    "cap_analysis = CAP()\n",
    "\n",
    "# Deriving CAPs from the merged timeseries data\n",
    "cap_analysis.get_caps(\n",
    "    merged_dicts[\"merged\"], n_clusters=range(2, 8), cluster_selection_method=\"davies_bouldin\", show_figs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then each reduced subject timeseries (representing a session or task) can be used to compute the temporal dynamics\n",
    "of the previously identified CAPs from the merged timeseries. These files can then be used to perform analyses\n",
    "assessing how to the same CAPs changed across time, tasks, or both time and tasks. Note that if ``standardize`` was set\n",
    "to True in ``CAP.get_caps()``, then the column (ROI) means and standard deviations computed from the concatenated data\n",
    "used to obtain the CAPs are also used to standardize each subject in the timeseries data inputted into\n",
    "``CAP.calculate_metrics()``. This ensures proper CAP assignments for each subjects frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cap_analysis.calculate_metrics(\n",
    "    merged_dicts[\"dict_0\"],\n",
    "    continuous_runs=False,\n",
    "    metrics=[\"persistence\"],\n",
    "    output_dir=os.getcwd(),\n",
    "    prefix_filename=\"session-pre\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that due to each subject only having a single run, the run names do not change to \"run-continuous\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_analysis.calculate_metrics(\n",
    "    merged_dicts[\"dict_1\"],\n",
    "    continuous_runs=True,\n",
    "    metrics=[\"persistence\"],\n",
    "    output_dir=os.getcwd(),\n",
    "    prefix_filename=\"session-post\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
