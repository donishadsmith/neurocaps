{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Using ``TimeseriesExtractor``\n",
    "This module is designed to perform timeseries extraction, nuisance regression, and visualization. Additionally, it\n",
    "generates the necessary dictionary structure required for ``CAP``. If the BOLD images have not been preprocessed using\n",
    "fMRIPrep (or a similar pipeline), the dictionary structure can be manually created.\n",
    "\n",
    "The output in the `Extracting Timeseries` section is generated from a test run using GitHub Actions. This test uses\n",
    "a truncated version of the open dataset provided by [Laumann & Poldrack](https://openfmri.org/dataset/ds000031/)\n",
    "and was obtained from the OpenfMRI database, accession number ds000031."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download packages\n",
    "try:\n",
    "  import neurocaps\n",
    "except:\n",
    "  !pip install neurocaps[windows,demo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Timeseries\n",
    "\n",
    "Download test dataset used for Github Actions from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, sys\n",
    "\n",
    "demo_dir = \"neurocaps_demo\"\n",
    "os.makedirs(demo_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(\"neurocaps_demo/data/dset\"):\n",
    "    if sys.platform != \"win32\":\n",
    "        cmd = \"\"\"\n",
    "            cd neurocaps_demo\n",
    "            git clone --depth 1 --filter=blob:none --sparse https://github.com/donishadsmith/neurocaps.git\n",
    "            cd neurocaps\n",
    "            git sparse-checkout set tests/data/dset\n",
    "            \"\"\"\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        repo_dir = os.path.join(demo_dir, \"neurocaps\")\n",
    "\n",
    "        # Enable git longpath\n",
    "        subprocess.run(\n",
    "            [\"git\", \"config\", \"--global\", \"core.longpaths\", \"true\"],\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"git\",\n",
    "                \"clone\",\n",
    "                \"--depth\",\n",
    "                \"1\",\n",
    "                \"--filter=blob:none\",\n",
    "                \"--sparse\",\n",
    "                \"https://github.com/donishadsmith/neurocaps.git\",\n",
    "            ],\n",
    "            check=True,\n",
    "            cwd=demo_dir,\n",
    "        )\n",
    "\n",
    "        subprocess.run(\n",
    "            [\"git\", \"sparse-checkout\", \"set\", \"tests/data/dset\"],\n",
    "            check=True,\n",
    "            cwd=repo_dir,\n",
    "        )\n",
    "\n",
    "    # Rename folder\n",
    "    os.makedirs(\"neurocaps_demo/data\", exist_ok=True)\n",
    "    os.rename(\"neurocaps_demo/neurocaps/tests/data/dset\", \"neurocaps_demo/data/dset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when an asterisk follows a name, all confounds that start with the preceding term will be automatically included.\n",
    "For example, placing an asterisk after cosine (cosine*) will utilize all parameters that begin with cosine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurocaps.extraction import TimeseriesExtractor\n",
    "\n",
    "confounds = [\"cosine*\", \"a_comp_cor*\", \"rot*\"]\n",
    "\n",
    "parcel_approach = {\"Schaefer\": {\"n_rois\": 100, \"yeo_networks\": 7, \"resolution_mm\": 2}}\n",
    "\n",
    "extractor = TimeseriesExtractor(\n",
    "    space=\"MNI152NLin2009cAsym\",\n",
    "    parcel_approach=parcel_approach,\n",
    "    standardize=True,\n",
    "    use_confounds=True,\n",
    "    detrend=True,\n",
    "    low_pass=0.15,\n",
    "    high_pass=None,\n",
    "    confound_names=confounds,\n",
    "    fd_threshold=0.35,\n",
    ")\n",
    "\n",
    "extractor.get_bold(\n",
    "    bids_dir=\"neurocaps_demo/data/dset\",\n",
    "    session=\"002\",\n",
    "    task=\"rest\",\n",
    "    pipeline_name=\"fmriprep_1.0.0/fmriprep\",\n",
    "    tr=1.2,\n",
    "    progress_bar=True,  # Parameter available in versions >= 0.21.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``print`` can be used to return a string representation of the ``TimeseriesExtractor`` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted timeseries is stored as a nested dictionary and can be accessed using the ``subject_timeseries``\n",
    "property. The ``TimeseriesExtractor`` class has several\n",
    "[properties](https://neurocaps.readthedocs.io/en/stable/generated/neurocaps.extraction.TimeseriesExtractor.html#properties)\n",
    "**Some properties can also be used as setters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extractor.subject_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting Quality Control Metrics\n",
    "<font size=\"3\">Checking number of censored frames, interpolated frames, and continuous high motion stats using the `self.report_qc` method. Only censored frames with valid data on both sides are interpolated, while censored frames at the edge of the timeseries (including frames that border censored edges) are always scrubbed and counted in \"Frames_Scrubbed\". In the data, the last frame is the only one with an FD > 0.35. Additionally, [scipy's Cubic Spline](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.CubicSpline.html) is used to only interpolate censored frames.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.report_qc(output_dir=demo_dir, filename=\"qc.csv\", return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.timeseries_to_pickle(output_dir=demo_dir, filename=\"rest_Schaefer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing a region\n",
    "extractor.visualize_bold(subj_id=\"01\", run=\"001\", region=\"Vis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing a several nodes\n",
    "extractor.visualize_bold(subj_id=\"01\", run=\"001\", roi_indx=[0, 1, 2])\n",
    "extractor.visualize_bold(subj_id=\"01\", run=\"001\", roi_indx=[\"LH_Vis_1\", \"LH_Vis_2\", \"LH_Vis_3\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
